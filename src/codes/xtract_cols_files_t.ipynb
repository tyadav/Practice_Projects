{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries \n",
    "import pandas as pd\n",
    "import os \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating main directory to store all the files \n",
    "main_dir_path = 'C:/Users/TejYadav/Desktop/All_Files'\n",
    "os.mkdir(main_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all the paths for a particular file name. Checks all the directories and sub-directories \n",
    "\n",
    "def get_paths(folder_name,file_name):\n",
    "    \n",
    "    path = \"C:/Users/Tej Yadav/Desktop/V codes/Data Files for Machine Learning/\"+(folder_name)+\"/\"\n",
    "\n",
    "    all_paths = []\n",
    "    \n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if (file_name) in file:\n",
    "                all_paths.append(os.path.join(r, file))\n",
    "   \n",
    "    return all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_columns(fname,cnames):\n",
    "    new_cnames = []\n",
    "    for i in cnames:\n",
    "        new_cnames.append(fname+\"_\"+i)\n",
    "    return new_cnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate the output file for a particular file name present in a folder named folder name and extract attributes defined by \n",
    "# attribute name \n",
    "\n",
    "# output file format - main_dir_path + sheet_dir_path + input_file_name.csv\n",
    "def generate_file(folder_name,file_names,attribute_name,input_name):\n",
    "    \n",
    "    dframe_file = pd.DataFrame()\n",
    "    output_dframe = pd.DataFrame()\n",
    "    \n",
    "    attribute_name = attribute_name.encode('utf-8')\n",
    "    attribute_name = attribute_name.strip()\n",
    "    attribute_names = attribute_name.split(\"\\n\")\n",
    "    \n",
    "        \n",
    "    for fname in file_names:\n",
    "        all_paths_files = get_paths(folder_name,fname)\n",
    "        \n",
    "        if len(file_names)>1:\n",
    "            temp_fname = fname.replace(\".csv\",\"\")\n",
    "            new_attribute_names = new_columns(temp_fname,attribute_names)\n",
    "\n",
    "        for j in range(len(all_paths_files)):\n",
    "            dframe = pd.read_csv(all_paths_files[j])\n",
    "            \n",
    "            if j == 0:\n",
    "                    dframe_file = dframe.loc[:,attribute_names]\n",
    "\n",
    "                    if len(file_names)>1:\n",
    "                        dframe_file.columns = new_attribute_names\n",
    "            else:\n",
    "                temp_df = dframe.loc[:,attribute_names] \n",
    "                if len(file_names)>1:\n",
    "                    temp_df.columns = new_attribute_names\n",
    "                dframe_file.append(temp_df,ignore_index=True)\n",
    "\n",
    "        output_dframe = pd.concat([output_dframe,dframe_file],axis=1)\n",
    "        \n",
    "    return output_dframe    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-6-a912433b5c0c>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-a912433b5c0c>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    xls = pd.ExcelFile('C:\\Users\\TejYadav\\Desktop\\V codes\\WIP_V2.1.xlsx')\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# To read input xlsx file \n",
    "\n",
    "xls = pd.ExcelFile('C:\\Users\\TejYadav\\Desktop\\V codes\\WIP_V2.1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-82bd4646599b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Getting names of all the worksheets from a workbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mall_sheet_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msheet_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_sheet_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xls' is not defined"
     ]
    }
   ],
   "source": [
    "# Getting names of all the worksheets from a workbook \n",
    "\n",
    "all_sheet_names = xls.sheet_names\n",
    "print(all_sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that uses other functions to extract particular attributes \n",
    "\n",
    "def extract_cols(sheets):\n",
    "    global main_dir_path\n",
    "    for sheet_name in sheets:\n",
    "        print(sheet_name)\n",
    "        \n",
    "        if str(sheet_name) != \"System Pump\":\n",
    "            \n",
    "            dframe_sheet = pd.read_excel(xls,sheetname=sheet_name)\n",
    "            records,cols = (dframe_sheet.shape)\n",
    "            \n",
    "            dframe_for_each_sheet = pd.DataFrame()\n",
    "            result_df = pd.DataFrame()\n",
    "            \n",
    "            for i in range(0,records):\n",
    "                \n",
    "                folder_name = str(dframe_sheet.loc[i,'Folder Name'])\n",
    "                file_name = str(dframe_sheet.loc[i,'File Name'])\n",
    "                file_names = file_name.split(\"\\n\")\n",
    "                attribute_name = (dframe_sheet.loc[i,'Column Name'])\n",
    "                input_name = str(dframe_sheet.loc[i,'Inputs'])\n",
    "                if isinstance(attribute_name, unicode):\n",
    "                \n",
    "                    result_df = generate_file(folder_name,file_names,attribute_name,input_name)\n",
    "                \n",
    "                    dframe_for_each_sheet = pd.concat([dframe_for_each_sheet,result_df],axis=1)\n",
    "                    \n",
    "            final_records,final_cols=(dframe_for_each_sheet.shape)\n",
    "            output_file_path = str(main_dir_path + '/' + sheet_name + '_all_attributes.csv')\n",
    "            o_file = open(output_file_path,mode=\"w\")\n",
    "            dframe_for_each_sheet.to_csv(output_file_path,sep=',', encoding='utf-8',index = False)\n",
    "            print(output_file_path)\n",
    "            print(final_cols)\n",
    "\n",
    "        elif str(sheet_name) == \"System Pump\":\n",
    "            \n",
    "            dframe_sheet = pd.read_excel(xls,sheetname=sheet_name)\n",
    "            dframe_for_each_sheet = pd.DataFrame()\n",
    "            result_df = pd.DataFrame()\n",
    "            \n",
    "            records,cols = (dframe_sheet.shape)\n",
    "            \n",
    "            for i in range(0,9):\n",
    "               \n",
    "                folder_name = str(dframe_sheet.loc[i,'Folder Name'])\n",
    "                file_name = str(dframe_sheet.loc[i,'File Name'])\n",
    "                file_names = file_name.split(\"\\n\")\n",
    "                attribute_name = (dframe_sheet.loc[i,'Column Name'])\n",
    "                \n",
    "                if isinstance(attribute_name, unicode) and folder_name != ' ' and folder_name != 'nan' and file_name != ' ' and file_name != 'nan':\n",
    "                    result_df = generate_file(folder_name,file_names,attribute_name,input_name)\n",
    "                    dframe_for_each_sheet = pd.concat([dframe_for_each_sheet,result_df],axis=1)\n",
    "                   \n",
    "            # To consider these 15 files for each of the inputs \n",
    "            \n",
    "            system_pump_file_names = ['crah_server1_A_1.csv', 'crah_server1_A_2.csv', 'crah_server1_A_3.csv', 'crah_server1_A_4.csv',\n",
    "                                    'crah_server1_B_1.csv', 'crah_server1_B_2.csv', 'crah_server1_B_3.csv', 'crah_server1_B_4.csv', 'crah_storage1_A_1.csv', 'crah_storage1_B_1.csv',\n",
    "                                    'crah_ups_A_1.csv', 'crah_ups_A_2', 'crah_ups_B_1.csv', 'crah_ups_B_2.csv', 'crah_wan1_A_1.csv']\n",
    "            \n",
    "            for i in range(9,records):\n",
    "               \n",
    "                folder_name = str(dframe_sheet.loc[i,'Folder Name'])\n",
    "                file_name = str(dframe_sheet.loc[i,'File Name'])\n",
    "                file_names = file_name.split(\"\\n\")\n",
    "                attribute_name = (dframe_sheet.loc[i,'Column Name'])\n",
    "                input_name = str(dframe_sheet.loc[i,'Inputs'])\n",
    "                \n",
    "                if file_name != 'nan' and folder_name != 'nan' and file_name != ' ' and folder_name != ' ' and isinstance(attribute_name,unicode) :\n",
    "                    data_available = True\n",
    "                    result_df = generate_file(folder_name,system_pump_file_names,attribute_name,input_name)\n",
    "                    dframe_for_each_sheet = pd.concat([dframe_for_each_sheet,result_df],axis=1)\n",
    "                \n",
    "            final_records,final_cols=(dframe_for_each_sheet.shape)\n",
    "            \n",
    "            output_file_path = str(main_dir_path + '/' + sheet_name + '_all_attributes.csv')\n",
    "            o_file = open(output_file_path,mode=\"w\")\n",
    "            dframe_for_each_sheet.to_csv(output_file_path,sep=',', encoding='utf-8',index = False)\n",
    "            print(output_file_path)\n",
    "            print(final_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files generated\n",
      "Condenser Pump\n",
      "C:/Users/TejYadav/Desktop/All_Files/Condenser Pump_all_attributes.csv\n",
      "0\n",
      "Evaporator Pump\n",
      "C:/Users/TejYadav/Desktop/All_Files/Evaporator Pump_all_attributes.csv\n",
      "0\n",
      "System Pump\n",
      "C:/Users/TejYadav/Desktop/All_Files/System Pump_all_attributes.csv\n",
      "0\n",
      "Cooling Tower\n",
      "C:/Users/TejYadav/Desktop/All_Files/Cooling Tower_all_attributes.csv\n",
      "0\n",
      "Compression Chiller\n",
      "C:/Users/TejYadav/Desktop/All_Files/Compression Chiller_all_attributes.csv\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Calling function for considering all the sheets in the input workbook\n",
    "print(\"Output files generated\")\n",
    "extract_cols(all_sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
